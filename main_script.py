import streamlit as st
import json
import pymupdf as fitz  # PyMuPDF
from openai import OpenAI
from googletrans import Translator
import time
import tempfile
import io
import hashlib
import os
import re

# -------------------------------
# INITIALIZATION
# -------------------------------
client = OpenAI()
translator = Translator()

st.set_page_config(
    page_title="üìò Multilingual Oral Board Exam Trainer",
    page_icon="üß†",
    layout="centered"
)

st.title("üß† Multilingual Oral Board Exam Trainer")
st.markdown("Upload a PDF, generate short-answer questions, answer in your chosen language, and get bilingual feedback.")
st.markdown("If you are using a mobile device, make sure to use a pdf file that is downloaded locally, and not uploaded from a Cloud Drive to prevent an upload error.")

# -------------------------------
# SESSION STATE INITIALIZATION
# -------------------------------
if "question_set_id" not in st.session_state:
    st.session_state["question_set_id"] = 0

if "generate_new_set" not in st.session_state:
    st.session_state["generate_new_set"] = False

if "questions" not in st.session_state:
    st.session_state["questions"] = []

if "user_answers" not in st.session_state:
    st.session_state["user_answers"] = []

if "evaluations" not in st.session_state:
    st.session_state["evaluations"] = []

if "selected_prev_set" not in st.session_state:
    st.session_state["selected_prev_set"] = None

if "mode" not in st.session_state:
    st.session_state["mode"] = "idle"  # idle | generate | retry

if "current_set_id" not in st.session_state:
    st.session_state["current_set_id"] = None

if "generate_now" not in st.session_state:
    st.session_state["generate_now"] = False

# -------------------------------
# SAFE TRANSLATION FUNCTION (CACHED)
# -------------------------------
def _looks_english(text):
    english_words = ["the", "and", "identify", "make", "open"]
    hits = sum(word in text.lower() for word in english_words)
    return hits >= 2

@st.cache_data(show_spinner=False)
def safe_translate(text, target_language_name):
    """Translate text safely with fallback to google translate and skip English."""
    executed_ukrainian_prompt = False
    if not text or not text.strip():
        return text
                
    # ‚úÖ Skip translation for English
    if target_language_code == "en":
        return text
    try:
        if target_language_code == "uk":
            executed_ukrainian_prompt = True
            prompt = f"""
            You are a professional medical translator and Ukrainian-speaking clinician.
            
            TASK:
            Translate the following medical exam content into NATURAL, CLINICALLY CORRECT UKRAINIAN.
            
            TARGET STYLE:
            - Ukrainian as used by medical residents in Ukraine
            - Natural Ukrainian syntax (not word-for-word English)
            - Clear, concise, exam-appropriate phrasing
            
            TERMINOLOGY RULES:
            - Use standard Ukrainian medical terminology where it exists
            - If a term is commonly used in English/Latin in Ukrainian practice, keep it (e.g. CT, MRI, sepsis)
            - Do NOT invent rare or archaic Ukrainian equivalents
            - Do NOT translate proper disease names unnecessarily
            
            QUALITY RULES:
            - Preserve the full clinical meaning
            - Minor rephrasing is allowed to improve clarity
            - Avoid literal English word order
            - Avoid Russian-style constructions
            
            OUTPUT RULES:
            - Output ONLY Ukrainian
            - No English
            - No explanations
            - No quotes
            
            TEXT:
            {text}
            """
            
        else:
            prompt = f"""
            You are a professional medical translator.
            
            TASK:
            Translate the following medical text into **{target_language_name}**.
            
            STRICT RULES:
            - Output MUST be written entirely in {target_language_name}
            - DO NOT keep English sentences
            - Medical terms may remain Latin-based if appropriate
            - Do NOT summarize or paraphrase
            - If unsure, still translate
            - DO NOT write in English
            
            TEXT:
            {text}
            """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        translated = response.choices[0].message.content.strip()

        # üîé Post-check: still looks English?
        if _looks_english(translated):
            raise ValueError("GPT returned English")

        return translated, executed_ukrainian_prompt
    except Exception:
        pass
        
    try:
        translated = translator.translate(text, dest=target_language_name)
        return translated.text if translated else text
    except Exception:
        pass

    return text

#Google translate first
def ui_translate(text, target_language_name):
    """Translate text safely with fallback to ChatGPT and skip English."""
    if not text or not text.strip():
        return text
    if target_language_code == "en":
        return text
    try:
        translated = translator.translate(text, dest=target_language_name)
        if translated and hasattr(translated, "text"):
            return translated.text
    except Exception:
        pass
    
    try:
        prompt = f"""Translate this text into {target_language_name}:\n{text}"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return response.choices[0].message.content.strip()    
    except Exception:
        pass
    return text
    
# -------------------------------
# LANGUAGE SELECTION
# -------------------------------
language_map = {
    'English': 'en',
    'Afrikaans': 'af',
    'Albanian': 'sq',
    'Amharic': 'am',
    'Arabic': 'ar',
    'Armenian': 'hy',
    'Azerbaijani': 'az',
    'Basque': 'eu',
    'Belarusian': 'be',
    'Bengali': 'bn',
    'Bosnian': 'bs',
    'Bulgarian': 'bg',
    'Catalan': 'ca',
    'Cebuano': 'ceb',
    'Chichewa': 'ny',
    'Chinese (Simplified)': 'zh-cn',
    'Chinese (Traditional)': 'zh-tw',
    'Corsican': 'co',
    'Croatian': 'hr',
    'Czech': 'cs',
    'Danish': 'da',
    'Dutch': 'nl',
    'Esperanto': 'eo',
    'Estonian': 'et',
    'Filipino': 'tl',
    'Finnish': 'fi',
    'French': 'fr',
    'Frisian': 'fy',
    'Galician': 'gl',
    'Georgian': 'ka',
    'German': 'de',
    'Greek': 'el',
    'Gujarati': 'gu',
    'Haitian Creole': 'ht',
    'Hausa': 'ha',
    'Hawaiian': 'haw',
    'Hebrew': 'he',
    'Hindi': 'hi',
    'Hmong': 'hmn',
    'Hungarian': 'hu',
    'Icelandic': 'is',
    'Igbo': 'ig',
    'Indonesian': 'id',
    'Irish': 'ga',
    'Italian': 'it',
    'Japanese': 'ja',
    'Javanese': 'jw',
    'Kannada': 'kn',
    'Kazakh': 'kk',
    'Khmer': 'km',
    'Korean': 'ko',
    'Kurdish (Kurmanji)': 'ku',
    'Kyrgyz': 'ky',
    'Lao': 'lo',
    'Latin': 'la',
    'Latvian': 'lv',
    'Lithuanian': 'lt',
    'Luxembourgish': 'lb',
    'Macedonian': 'mk',
    'Malagasy': 'mg',
    'Malay': 'ms',
    'Malayalam': 'ml',
    'Maltese': 'mt',
    'Maori': 'mi',
    'Marathi': 'mr',
    'Mongolian': 'mn',
    'Myanmar (Burmese)': 'my',
    'Nepali': 'ne',
    'Norwegian': 'no',
    'Odia': 'or',
    'Pashto': 'ps',
    'Persian': 'fa',
    'Polish': 'pl',
    'Portuguese': 'pt',
    'Punjabi': 'pa',
    'Romanian': 'ro',
    'Russian': 'ru',
    'Samoan': 'sm',
    'Scots Gaelic': 'gd',
    'Serbian': 'sr',
    'Sesotho': 'st',
    'Shona': 'sn',
    'Sindhi': 'sd',
    'Sinhala': 'si',
    'Slovak': 'sk',
    'Slovenian': 'sl',
    'Somali': 'so',
    'Spanish': 'es',
    'Sundanese': 'su',
    'Swahili': 'sw',
    'Swedish': 'sv',
    'Tajik': 'tg',
    'Tamil': 'ta',
    'Telugu': 'te',
    'Thai': 'th',
    'Turkish': 'tr',
    'Ukrainian': 'uk',
    'Urdu': 'ur',
    'Uyghur': 'ug',
    'Uzbek': 'uz',
    'Vietnamese': 'vi',
    'Welsh': 'cy',
    'Xhosa': 'xh',
    'Yiddish': 'yi',
    'Yoruba': 'yo',
    'Zulu': 'zu',
}

target_language_name = st.selectbox("üåç Select your language:", list(language_map.keys()), index=0)
target_language_code = language_map[target_language_name]

def bilingual_text(en_text):
    """Display English + translated text, unless English is selected."""
    if target_language_code == "en":
        return en_text
    #translated = safe_translate(en_text, target_language_name)
    translated, uk_used = safe_translate(en_text, target_language_name)

    if uk_used:
        st.success("üá∫üá¶ Ukrainian medical prompt was used")
    return f"{en_text}\n**({target_language_name})**: {translated}"

def bilingual_text_ui(en_text):
    """Display English + translated text, unless English is selected. Function specifically for not medically important information."""
    if target_language_code == "en":
        return en_text
    translated = ui_translate(en_text, target_language_name)
    return f"{en_text}\n**({target_language_name})**: {translated}"

# -------------------------------
# PDF UPLOAD
# -------------------------------
uploaded_file = st.file_uploader(bilingual_text_ui("üìÑ Upload a PDF file"), type=["pdf"])

def extract_text_from_pdf(uploaded_file):
    text = ""
    with fitz.open(stream=uploaded_file.read(), filetype="pdf") as pdf_doc:
        for page in pdf_doc:
            text += page.get_text("text")
    return text
    
if uploaded_file:
    if "pdf_text" not in st.session_state or st.session_state.get("uploaded_file_name") != uploaded_file.name:
        pdf_text = extract_text_from_pdf(uploaded_file)
        st.session_state["pdf_text"] = pdf_text
        st.session_state["uploaded_file_name"] = uploaded_file.name
        st.success(bilingual_text_ui("‚úÖ PDF uploaded successfully!"))
    else:
        pdf_text = st.session_state["pdf_text"]

pdf_text = st.session_state.get("pdf_text", "")


# -------------------------------
# Question Topic Extraction
# -------------------------------
def extract_topics_from_questions(questions):
    """
    Extract short topic labels from a list of questions.
    """
    prompt = f"""
Extract a concise topic label (2‚Äì5 words) for each of the following oral board questions.
Return ONLY a JSON list of UNIQUE topic strings.

QUESTIONS:
{json.dumps([q["question_en"] for q in questions], indent=2)}
"""
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    raw = response.choices[0].message.content.strip()
    raw = re.sub(r"```(?:json)?|```", "", raw).strip()
    return json.loads(raw)


def get_used_topics():
    """
    Aggregate all previously used topics from session state.
    """
    used = set()
    for s in st.session_state.get("all_question_sets", []):
        for t in s.get("topics", []):
            used.add(t)
    return sorted(list(used))

# -------------------------------
# QUESTION GENERATION (Single GPT Call, Bilingual, Previous Sets)
# -------------------------------
if pdf_text:
    st.subheader(bilingual_text_ui("üß© Step 1: Generate Short-Answer Questions"))

    num_questions = st.slider(bilingual_text_ui("Number of questions to generate:"),1, 10, key="num_questions")

    # Trigger generation if user clicks "Generate Questions" OR new set flag is set
    if st.button(bilingual_text_ui("‚ö° Generate Questions")):
        st.session_state["generate_now"] = True
        st.session_state["question_set_id"] += 1
        st.rerun()
            

    if st.session_state.get("generate_now"):
        st.session_state["generate_now"] = False
    
        pdf_text = st.session_state["pdf_text"]
        progress = st.progress(0, text=bilingual_text_ui("Generating questions... please wait"))


        # -------------------------------
        # 1Ô∏è‚É£ Prompt GPT to generate all questions
        # -------------------------------
        used_topics = get_used_topics()
        prompt = f"""
    You are an expert medical educator.
    Generate {num_questions} concise short-answer questions and their answer keys based on the following content.
    PREVIOUSLY USED TOPICS (avoid these unless no alternatives remain): {json.dumps(used_topics, indent=2)}
    Your target audience is residents.
    
    TASK:
    1. Identify ALL major topics in the source material.
    2. Exclude any topics listed above.
    3. Randomly select {num_questions} DIFFERENT remaining topics.
    4. Write ONE concise short-answer question per topic, structured like a Royal College of Physicians and Surgeons oral boards exam.
    
    RULES:
    - Ensure the questions are **proportional across the manual**, covering all major topics.
    - Each question must test a DIFFERENT topic
    - Do NOT generate multiple questions from the same subsection
    - Do NOT follow the order of the manual
    - Do NOT repeat themes from earlier question sets
    - Focus on clinical relevance
    - If surgical content exists, include presentation, approach, and management
    - Questions should resemble Royal College oral board style
    
    Return ONLY JSON in this format:
    [
      {{"topic": "string", "question": "string", "answer_key": "string"}}
    ]
    
    SOURCE TEXT:
    {pdf_text}
    """
        try:
            response = client.chat.completions.create(
                model="gpt-4.1-mini-2025-04-14",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.8
            )
            raw = response.choices[0].message.content.strip()
            raw = re.sub(r"```(?:json)?|```", "", raw).strip()
            all_items = json.loads(raw)
    
            # Normalize structure
            all_questions = [
                {
                    "topic": item.get("topic", "").strip(),
                    "question": item.get("question", "").strip(),
                    "answer_key": item.get("answer_key", "").strip()
                }
                for item in all_items
                if item.get("question") and item.get("answer_key")
            ]
            
            progress.progress(50, text=bilingual_text_ui("Questions generated. Translating..."))
    
        except Exception as e:
            st.error(bilingual_text_ui(f"‚ö†Ô∏è Question generation failed: {e}"))
            all_questions = []
    
        if all_questions:
            # -------------------------------
            # 2Ô∏è‚É£ Bilingual translation (batched)
            # -------------------------------
            bilingual_questions = []
    
            if target_language_name == "English":
                for q in all_questions:
                    bilingual_questions.append({
                        "question_en": q.get("question", ""),
                        "answer_key_en": q.get("answer_key", "")
                    })
            else:
                # Prepare batch text for GPT translation to minimize API calls
                batch_text = "\n\n".join(
                    [f"Q: {q.get('question','')}\nA: {q.get('answer_key','')}" for q in all_questions]
                )
                translation_prompt = f"""
    Translate the following questions and answers into {target_language_name}.
    Return JSON in the same order with this format:
    [
    {{"question_translated": "string", "answer_key_translated": "string"}}
    ]
    
    TEXT:
    {batch_text}
    """
                try:
                    translation_resp = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": translation_prompt}],
                        temperature=0
                    )
                    raw_trans = translation_resp.choices[0].message.content.strip()
                    raw_trans = re.sub(r"```(?:json)?|```", "", raw_trans).strip()
                    translations = json.loads(raw_trans)
                except Exception:
                    translations = [{}] * len(all_questions)
    
                for q, t in zip(all_questions, translations):
                    bilingual_questions.append({
                        "question_en": q.get("question", ""),
                        "answer_key_en": q.get("answer_key", ""),
                        "question_translated": t.get("question_translated", ""),
                        "answer_key_translated": t.get("answer_key_translated", "")
                    })
    
            # -------------------------------
            # 3Ô∏è‚É£ Save to session state
            # -------------------------------
            st.session_state["questions"] = bilingual_questions
            st.session_state["user_answers"] = [""] * len(bilingual_questions)
            progress.progress(100, text=bilingual_text_ui("‚úÖ Done! Questions ready."))
    
            # -------------------------------
            # 4Ô∏è‚É£ Store previous sets
            # -------------------------------
            if "all_question_sets" not in st.session_state:
                st.session_state["all_question_sets"] = []
    
            topics = [q.get("topic", "") for q in all_questions if q.get("topic")]
            
            all_sets = st.session_state.get("all_question_sets", [])
            new_set_id = len(all_sets)  # unique incremental id
            
            st.session_state["all_question_sets"].append({
                "set_id": new_set_id,
                "questions": bilingual_questions,
                "topics": topics,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            })

            st.session_state["current_set_id"] = new_set_id
            st.success(bilingual_text_ui(f"Generated {len(bilingual_questions)} representative questions successfully!"))

# -------------------------------
# USER ANSWERS (WITH AUDIO INPUT)
# -------------------------------
if st.session_state["questions"]:
    st.subheader(bilingual_text_ui("üß† Step 2: Answer the Questions"))

    questions = st.session_state["questions"]

    if "user_answers" not in st.session_state or len(st.session_state["user_answers"]) != len(questions):
        st.session_state["user_answers"] = [""] * len(questions)

    for i, q in enumerate(questions):
        st.markdown(f"### Q{i+1}. {q.get('question_en', '')}")

        if target_language_name == "English":
            pass
        else:    
            st.markdown(f"**({target_language_name}):** {q.get('question_translated', '')}")

        st.markdown(bilingual_text_ui("üé§ Dictate your answer (you can record multiple times):"))
        qid = st.session_state["question_set_id"]
        audio_data = st.audio_input(
            "",
            key=f"audio_input_{qid}_{i}"
        )

        transcriptions_key = f"transcriptions_{i}"
        last_hash_key = f"last_audio_hash_{i}"
        if transcriptions_key not in st.session_state:
            st.session_state[transcriptions_key] = []
        if last_hash_key not in st.session_state:
            st.session_state[last_hash_key] = None

        dictated_text = ""
        
        if audio_data is not None:
            try:
                audio_bytes = audio_data.getvalue()
                audio_hash = hashlib.sha256(audio_bytes).hexdigest()
        
                if st.session_state.get(last_hash_key) == audio_hash:
                    st.info(bilingual_text_ui("This recording was already transcribed."), icon="‚ÑπÔ∏è")
                else:
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                        tmp_file.write(audio_bytes)
                        tmp_path = tmp_file.name
        
                    with open(tmp_path, "rb") as f:
                        transcription = client.audio.transcriptions.create(
                            model="whisper-1",
                            file=f
                        )
        
                    os.remove(tmp_path)
        
                    dictated_text = getattr(transcription, "text", "").strip()
        
                    if dictated_text:
                        # ‚úÖ Append to CURRENT text area value
                        existing_text = st.session_state.get(f"ans_{qid}_{i}", "").strip()
                        if existing_text:
                            new_text = f"{existing_text} {dictated_text}"
                        else:
                            new_text = dictated_text
        
                        st.session_state[f"ans_{qid}_{i}"] = new_text
                        st.session_state["user_answers"][i] = new_text
                        st.session_state[last_hash_key] = audio_hash
        
                        st.success(bilingual_text_ui("üéß Dictation appended to your answer."), icon="üé§")
                    else:
                        st.warning(bilingual_text_ui("‚ö†Ô∏è Transcription returned empty text."))
        
            except Exception as e:
                st.error(bilingual_text_ui(f"‚ö†Ô∏è Audio transcription failed: {e}"))

        label = bilingual_text_ui("‚úèÔ∏è Your Answer:")
        key = f"ans_{qid}_{i}"  # unified key
        existing_text = st.session_state.get(key, "").strip()
        if existing_text:
            new_text = f"{existing_text} {dictated_text}"
        else:
            new_text = dictated_text
        
        st.session_state[key] = new_text
        st.session_state["user_answers"][i] = new_text
        
        current_text = st.text_area(label, height=80, key=key)

    user_answers = st.session_state.get("user_answers", [])

    # -------------------------------
    # EVALUATION
    # -------------------------------
    def score_short_answers(user_answers, questions):
        grading_prompt = f"""
        You are a supportive Royal College oral boards examiner assessing RESIDENT-LEVEL answers.
        
        Your goal is to fairly assess clinical understanding, not to fail candidates.
        
        IMPORTANT GRADING PHILOSOPHY:
        - Full marks (9‚Äì10/10) are achievable for clear, correct, resident-appropriate answers
        - Do NOT require consultant-level depth for full credit
        - Award generous partial credit for correct core concepts
        - Minor omissions or wording issues should NOT heavily penalize the score
        - Answers may be brief, non-native English, or in another language
        
        SCORING RUBRIC (0‚Äì10):
        - 9‚Äì10: Correct core concepts, clinically sound, safe management; minor details may be missing
        - 7‚Äì8: Mostly correct with good understanding; some gaps or imprecision
        - 5‚Äì6: Partial understanding; correct ideas but important omissions
        - 3‚Äì4: Limited understanding; some correct fragments
        - 1‚Äì2: Minimal understanding
        - 0: Unsafe or completely incorrect
        
        INSTRUCTIONS:
        1. Focus on whether the candidate demonstrates SAFE and CORRECT clinical reasoning
        2. Compare the response to the expected answer key, but do NOT require exact wording
        3. If the core idea is present, award at least 6/10
        4. Be especially fair to concise answers typical of oral exams
        
        Return ONLY JSON:
        [
          {{
            "score": 0,
            "feedback": "Brief, constructive feedback explaining the score.",
            "model_answer": "A concise ideal resident-level answer."
          }}
        ]
        
        QUESTIONS AND RESPONSES:
        {json.dumps([
            {
                "question": q.get("question_en", ""),
                "expected": q.get("answer_key_en", ""),
                "response": a
            }
            for q, a in zip(questions, user_answers)
        ], indent=2)}
        """
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": grading_prompt}],
                temperature=0
            )
            raw = response.choices[0].message.content.strip()
            raw = re.sub(r"```(?:json)?|```", "", raw).strip()
            results = json.loads(raw)
            for r in results:
                r["feedback_translated"] = safe_translate(r.get("feedback", ""), target_language_name)
                r["model_answer_translated"] = safe_translate(r.get("model_answer", ""), target_language_name)
            return results
        except Exception as e:
            st.error(bilingual_text_ui(f"‚ö†Ô∏è Scoring failed: {e}"))
            return []

    if st.button(bilingual_text_ui("üöÄ Evaluate My Answers")):
        with st.spinner(bilingual_text_ui("Evaluating your answers...")):
            results = score_short_answers(user_answers, questions)
            st.session_state['evaluations'] = results

        if results:
            # -------------------------------
            # Compute total score
            # -------------------------------
            total_score = sum(r.get("score", 0) for r in results)
            max_score = len(results) * 10  # each question max 10 points
            percentage = round(total_score / max_score * 100, 1)
    
            st.success(bilingual_text_ui("‚úÖ Evaluation complete!"))
    
            # -------------------------------
            # Display total score
            # -------------------------------
            st.markdown(f"### üèÜ {bilingual_text_ui('Total Score')}: {total_score}/{max_score} ({percentage}%)")
            
            st.success(bilingual_text_ui("‚úÖ Evaluation complete!"))
            with st.expander(bilingual_text_ui("üìä Detailed Feedback")):
                for i, (q, r) in enumerate(zip(questions, results)):
                    st.markdown(f"### Q{i+1}: {q.get('question_en', '')}")
                    
                    if target_language_name == "English":
                        st.markdown(f"**Score:** {r.get('score', 'N/A')} / 10")
                        st.markdown(f"**Feedback (English):** {r.get('feedback', '')}")
                        st.markdown(f"**Model Answer (English):** {r.get('model_answer', '')}")
                        st.markdown("---")

                    else:                    
                        st.markdown(f"**({target_language_name}): {q.get('question_translated', '')}**")
                        st.markdown(f"**Score:** {r.get('score', 'N/A')} / 10")
                        st.markdown(f"**Feedback (English):** {r.get('feedback', '')}")
                        st.markdown(f"**Feedback ({target_language_name}):** {r.get('feedback_translated', '')}")
                        st.markdown(f"**Model Answer (English):** {r.get('model_answer', '')}")
                        st.markdown(f"**Model Answer ({target_language_name}):** {r.get('model_answer_translated', '')}")
                        st.markdown("---")

        if st.session_state.get("all_question_sets"):
            with st.expander(bilingual_text_ui("üìö Topics Covered So Far")):
                for used_topic_item in get_used_topics():
                    st.write(bilingual_text_ui(used_topic_item))

        # -------------------------------
        # Previous Question Sets Viewer
        # -------------------------------
    debug = True
    if debug == True:
        pass
    else:
        if st.session_state.get("all_question_sets"):
        
            st.subheader(bilingual_text_ui("üìö Retry Previous Question Sets"))
        
            prev_sets = {s["set_id"]: s for s in st.session_state["all_question_sets"]}
            prev_set_ids = list(prev_sets.keys())
        
            if not prev_set_ids:
                st.info(bilingual_text_ui("No previous question sets available."))
            else:
                # Initialize selection ONCE
                if "selected_prev_set" not in st.session_state:
                    st.session_state["selected_prev_set"] = prev_set_ids[-1]
        
                # If selection somehow became invalid, recover gracefully
                if st.session_state["selected_prev_set"] not in prev_set_ids:
                    st.session_state["selected_prev_set"] = prev_set_ids[-1]
        
                selected_id = st.selectbox(
                    bilingual_text_ui("Select a previous question set to view:"),
                    options=prev_set_ids,
                    format_func=lambda sid: (
                        f"Set {sid+1}: "
                        + " | ".join(
                            q.get("question_en", "")
                            for q in prev_sets[sid]["questions"][:3]
                        )[:100]
                        + f"... ({prev_sets[sid]['timestamp']})"
                    ),
                    key="selected_prev_set"
                )
        
                selected_set = prev_sets[selected_id]
        
                # Preview
                with st.expander(bilingual_text_ui("üìÑ Preview Selected Question Set"), expanded=True):
                    for i, q in enumerate(selected_set["questions"]):
                        st.markdown(f"**Q{i+1}:** {q.get('question_en', '')}")
                        if target_language_code != "en":
                            st.markdown(f"*({target_language_name})* {q.get('question_translated','')}")
                        st.markdown("---")
        
                # Load button
                if st.button(bilingual_text_ui("üìÇ Load Selected Question Set")):
                    st.session_state["current_set_id"] = selected_id
                    st.session_state["questions"] = selected_set["questions"]
                    st.session_state["user_answers"] = [""] * len(selected_set["questions"])
                    st.session_state["evaluations"] = []
                    st.session_state["mode"] = "retry"
                    st.rerun()
                

    # -------------------------------
    # NEW BUTTON: Generate a new set of questions
    # -------------------------------
    if st.button(bilingual_text_ui("üîÑ Generate a New Set of Questions")):
        st.session_state["questions"] = []
        st.session_state["user_answers"] = []
        st.session_state["evaluations"] = []
        st.session_state["mode"] = "generate"
        st.session_state["generate_now"] = True
        st.session_state["question_set_id"] += 1
        st.rerun()
    
            
    url_instructors = "https://forms.gle/GdMqpvikomBRTcvJ6"
    url_students = "https://forms.gle/CWKRqptQhpdLKaj8A"
    st.write(bilingual_text_ui("Thank you for trying this multilingual short answer question generator! Please click on the following links to provide feedback to help improve this tool:"))
    st.markdown(bilingual_text_ui("Feedback form for instructors:"))
    st.markdown(url_instructors)
    st.markdown(bilingual_text_ui("Feedback form for students:"))
    st.markdown(url_students)
    if uk_used:
        st.write("translation successful")
